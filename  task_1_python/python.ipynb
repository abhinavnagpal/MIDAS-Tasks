{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TASK 1: A Python Problem</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</h5><b>Instructions</b></h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your codes are properly documented. We recommend the following:-\n",
    "Before each code block have a markdown block which mentions the following\n",
    "- What the code block is doing.\n",
    "- What is your intuition behind doing this? Why do you think it is useful?\n",
    "- For bigger code blocks also add comments in the block.\n",
    "- Keep everything in this notebook things which worked, things which did not work.\n",
    "- This notebook should be a snapshot of the process you follow to solve a Data\n",
    "  problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM\n",
    "##### You have to write a python script which can fetch all the tweets (as many as allowed by Twitter API) done by midas@IIITD twitter handle and dump the responses into JSONlines file.\n",
    "##### The other part of your script should be able to parse these JSONline files to display the following for every tweet in a tabular format.\n",
    "- The text of the tweet.\n",
    "- Date and time of the tweet.\n",
    "- The number of favorites/likes.\n",
    "- The number of retweets.\n",
    "- Number of Images present in Tweet. If no image returns None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries for completing the task\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import jsonlines as jsl\n",
    "import tweepy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Step 1: Initialize the variables and tweepy to access the API </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = '1114284772665126912-yIWbS51Mh0Xri4Hs1keqRBLMmorQMX'\n",
    "ACCESS_SECRET = 'WpLwxRQuiATZT520FoJBR1YpesuBucasTJ4yOuywYJ4cL'\n",
    "CONSUMER_KEY = 'C6jm3wI4AttxBBLwPHeY3LfiE'\n",
    "CONSUMER_SECRET = 'xoFnaDnn4yib6IGNWZIFHCtt4P8ZKehaqQikbORZObtg0dvKAE'\n",
    "\n",
    "# setup tweepy by authenticating the user credentials\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "# create the API\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get twitter data from midasiiitd timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = \"midasiiitd\"\n",
    "\n",
    "tweets_list = []\n",
    "\n",
    "for status in tweepy.Cursor(api.user_timeline, id=USER,tweet_mode=\"extended\").items():\n",
    "    tweets_list.append(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Dump the tweets in a jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'final.jsonl'\n",
    "\n",
    "for i in range(0,len(tweets_list)):\n",
    "    with open(path, 'a', encoding='utf8') as file: \n",
    "        json.dump(tweets_list[i]._json,file)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Function to get required data from a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fmt = ['png','jpeg','jpg']\n",
    "\n",
    "def get_data(tweet):\n",
    "    favourite_count = tweet['favorite_cout']\n",
    "    retweet_count = tweet['retweet_count']\n",
    "    number_image=0\n",
    "    if ('media' not in tweet['entities']):\n",
    "        number_image = None\n",
    "    else:\n",
    "        for media in tweet['entities']['media']:\n",
    "            if media['media_url'][-3:] in img_fmt:\n",
    "                number_image+=1\n",
    "    if (\"retweeted_status\" in tweet):\n",
    "        text = tweet['retweeted_status']['full_text']\n",
    "    else:\n",
    "        text = tweet['full_text']\n",
    "    return text,tweet['created_at'],favourite_count,retweet_count,number_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Reading tweet line by line from jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for line in open(path):\n",
    "    tweet = json.loads(line)\n",
    "    text,date_time,favourite_count,retweet_count,number_image = get_data(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Storing Data in a separate excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
